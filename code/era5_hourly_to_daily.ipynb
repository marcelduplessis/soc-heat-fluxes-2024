{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "375d1706-22bc-4dc1-b078-2de76c4d819b",
   "metadata": {},
   "source": [
    "### Convert the hourly ERA5 fields to daily and save as netCDF files\n",
    "\n",
    "A bit of data processing... Now we read in each of the 1-hour ERA5 data files and create daily means. This is because for the storm statistics, we use the daily mean variables so we don't care too much about sub-daily variability. This also makes the data much, much easier to work with. We also cut the latitudes at 40S because we don't use data north of that due to the strong subtropical, and western boundary current infleunce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b407be9a-2039-48ca-a285-245b7c11c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# load the modules needed for the data processing\n",
    "\n",
    "import sys\n",
    "sys.path.append('../functions/')\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "from storm_interstorm_id import storm_interstorm_id\n",
    "\n",
    "from adjust_lon_xr_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6dcd13c-d419-4231-80d2-c758ec8ffc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sea_ice_cover\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4aebecc116042b2bc42b90fbc3a434e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1981\n",
      "saving to file...\n",
      "1982\n",
      "saving to file...\n",
      "1983\n",
      "saving to file...\n",
      "1984\n",
      "saving to file...\n",
      "1985\n",
      "saving to file...\n",
      "1986\n",
      "saving to file...\n",
      "1987\n",
      "saving to file...\n",
      "1988\n",
      "saving to file...\n",
      "1989\n",
      "saving to file...\n",
      "1990\n",
      "saving to file...\n",
      "1991\n",
      "saving to file...\n"
     ]
    }
   ],
   "source": [
    "data_directory_out = '/Volumes/LaCie/Work/data/era5/DJF_1981_2023_daily_means/'\n",
    "\n",
    "vars = [\n",
    "    # 'winds', \n",
    "    # 'latent_heat_flux', \n",
    "    # 'sensible_heat_flux', \n",
    "    # '2m_dewpoint_temperature', \n",
    "    # '2m_temperature', \n",
    "    # 'net_solar_radiation',\n",
    "    # 'net_thermal_radiation',\n",
    "    'sea_ice_cover', \n",
    "    # 'sea_surface_temperature'\n",
    "]\n",
    "\n",
    "for var in vars:\n",
    "\n",
    "    data_directory_in  = '/Volumes/LaCie/Work/data/era5/DJF_1981_2023_hourly_means/DJF_1981_2023_' + var + '/*.nc'\n",
    "\n",
    "    file_list = sorted(glob(data_directory_in))\n",
    "\n",
    "    print(str(var))\n",
    "    \n",
    "    years = np.arange(1981, 1992)\n",
    "    \n",
    "    for y in tqdm(range(years.size)):\n",
    "    \n",
    "        year = years[y]\n",
    "        print(year)\n",
    "    \n",
    "        D = str(year) + '12.nc'\n",
    "        J = str(year+1) + '01.nc'\n",
    "        F = str(year+1) + '02.nc'\n",
    "        \n",
    "        # choose only the files that are dec, jan or feb\n",
    "        filtered_files = [file for file in file_list if file.endswith(D) or file.endswith(J) or file.endswith(F)]\n",
    "        \n",
    "        # load them into xarray\n",
    "        ds = xr.open_mfdataset(filtered_files, engine='netcdf4')\n",
    "    \n",
    "        # load the dataset\n",
    "        ds = ds.load()    \n",
    "\n",
    "        # cut the latitudes to our definition of the southern ocean\n",
    "        ds = ds.sel(latitude=slice(-40, -90))\n",
    "\n",
    "        # convert the fluxes to W m-2\n",
    "        if var == 'net_solar_radiation':\n",
    "        \n",
    "            ds['ssr'] = (('time', 'latitude', 'longitude'), (ds['ssr'] / 3600).data) \n",
    "\n",
    "        if var == 'net_thermal_radiation':\n",
    "        \n",
    "            ds['str'] = (('time', 'latitude', 'longitude'), (ds['str'] / 3600).data)                 \n",
    "    \n",
    "        # as this stage - resample the data to daily resolution, then do the calculations and adjust longitudes\n",
    "\n",
    "        ds_1D = ds.resample(time='1D').mean()\n",
    "        \n",
    "        if var == 'winds':\n",
    "            \n",
    "            # calculate the wind speed\n",
    "            ds_1D['ws'] = (('time', 'latitude', 'longitude'), np.sqrt(ds_1D['u10'].data**2 + ds_1D['v10'].data**2))\n",
    "        \n",
    "        # Adjust the longitudes to be -180 to 180\n",
    "        ds_1D = adjust_lon_xr_dataset(ds_1D)    \n",
    "    \n",
    "        print('saving to file...')\n",
    "        \n",
    "        ds_1D.to_netcdf(data_directory_out + str(var) + '_' + str(year) + '_DJF.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deda1be-9262-4c54-9e0f-1bed8c922410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
